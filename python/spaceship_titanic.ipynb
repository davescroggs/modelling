{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spaceship_data = pd.read_csv(\"../data/spaceship-titanic/train.csv\")\n",
    "\n",
    "spaceship_holdout = pd.read_csv(\"../data/spaceship-titanic/test.csv\")\n",
    "\n",
    "Xtrain, Xtest, Ytrain, Ytest = train_test_split(spaceship_data.loc[:,spaceship_data.columns != \"Transported\"], spaceship_data.Transported, train_size=0.8, )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature engineering\n",
    "\n",
    "- Remove name\n",
    "- Update role of id?\n",
    "- Character to categoricals\n",
    "- Do something with the NAs\n",
    "\n",
    "### Column datatypes\n",
    "\n",
    "| Column      |     datatype |\n",
    "|------------|-------| \n",
    "|PassengerId  |    object | \n",
    "|HomePlanet   |    object |\n",
    "|CryoSleep    |    object |\n",
    "|Cabin        |    object |\n",
    "|Destination  |    object |\n",
    "|Age          |   float64 |\n",
    "|VIP          |    object |\n",
    "|RoomService  |   float64 |\n",
    "|FoodCourt    |   float64 |\n",
    "|ShoppingMall |   float64 |\n",
    "|Spa          |   float64 |\n",
    "|VRDeck       |   float64 |\n",
    "|Name         |    object |\n",
    "|Transported  |      bool |\n",
    "\n",
    "### Methods/Functions for preprocessing\n",
    "\n",
    "- Pipeline, make_pipeline\n",
    "- UDF\n",
    "- Standard scaler?\n",
    "- Dealing with missing levels?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "cats = ['HomePlanet', 'CryoSleep', 'Cabin', 'Destination', 'VIP']\n",
    "\n",
    "conts = ['Age', 'RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']\n",
    "\n",
    "def impute_median(col):\n",
    "    col_med = np.nanmedian(col)\n",
    "    return col.fillna(col_med)\n",
    "\n",
    "def impute_mode(col):\n",
    "    col_mode = col.mode()\n",
    "    return col.fillna(col_mode)\n",
    "    \n",
    "\n",
    "def proc_data(df):\n",
    "    #df = df.copy()\n",
    "    df = df.drop(columns = [\"Name\", \"PassengerId\"], axis = 1)\n",
    "    # Impute median for continuous vars\n",
    "    df[conts] = df[conts].apply(impute_median)\n",
    "    # Impute mode for categoricals\n",
    "    df[cats] = df[cats].apply(impute_mode)\n",
    "    # Convert categorial columns explicitly\n",
    "    df[cats] = df[cats].apply(pd.Categorical)\n",
    "    df[cats] = df[cats].apply(lambda x: x.cat.codes)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning\n",
    "\n",
    "Functions\n",
    "- Randomised search cv:\n",
    "- Grid search cv:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': [600, 733, 866, 1000], 'max_features': ['auto', 'sqrt'], 'max_depth': [10, 35, 60, 85, 110, None], 'min_samples_split': [2, 5, 10], 'min_samples_leaf': [1, 2, 4], 'bootstrap': [True]}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 600, stop = 1000, num = 4)]\n",
    "# Number of features to consider at every split\n",
    "max_features = 'sqrt'\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 5)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True]\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "print(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://towardsdatascience.com/hyperparameter-tuning-the-random-forest-in-python-using-scikit-learn-28d2aa77dd74\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# Use the random grid to search for best hyperparameters\n",
    "# First create the base model to tune\n",
    "rf = RandomForestClassifier()\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 10, cv = 3, verbose=1, random_state=42, n_jobs = 1)\n",
    "# Fit the random search model\n",
    "Xtrain_data = proc_data(Xtrain)\n",
    "Ytrain_data = Ytrain.replace({True: \"Transported\", False: \"NotTransported\"})\n",
    "rf_random.fit(Xtrain_data, Ytrain_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 600, 'min_samples_split': 5, 'min_samples_leaf': 4, 'max_features': 'sqrt', 'max_depth': None, 'bootstrap': True}\n",
      "0.8871153293068738\n",
      "0.7860839562967222\n"
     ]
    }
   ],
   "source": [
    "print(rf_random.best_params_)\n",
    "\n",
    "Xtest_data = proc_data(Xtest)\n",
    "Ytest_data = Ytest.replace({True: \"Transported\", False: \"NotTransported\"})\n",
    "\n",
    "print (rf_random.score(Xtrain_data, Ytrain_data))\n",
    "print(rf_random.score(Xtest_data, Ytest_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model fit\n",
    "\n",
    " - Custom scorer: sklearn.metrics/make_scorer, takes udf with train/pred inputs + direction of optimisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_tuned = RandomForestClassifier()\n",
    "rf_tuned.set_params(**rf_random.best_params_)\n",
    "\n",
    "rf_tuned.fit(Xtrain_data, Ytrain_data)\n",
    "\n",
    "transported_pred = rf_tuned.predict(proc_data(spaceship_holdout))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "conds = {\"Transported\": True, \"NotTransported\": False}\n",
    "transported_pred = [conds[x] for x in transported_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_df = pd.DataFrame({'PassengerId': spaceship_holdout.PassengerId, 'isTransported': transported_pred})\n",
    "#out_df.to_csv()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
