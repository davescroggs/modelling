---
title: "Untitled"
output: github_document
---

# Sliced Episode 5 - predict the price of Airbnb listings in NYC

The evaluation metric for this competition is Root Mean Squared Logarithmic Error.

## Data dictionary

-   id: unique identifier

-   name: name of the listing

-   host_id: unique identifier for the host of the listing

-   host_name: name of the host

-   neighbourhood_group: borough where the listing is located (e.g., "Manhattan")

-   neighbourhood: neighborhood where the listing is located (e.g., "East Harlem")

-   latitude: latitude of the listing location

-   longitude: longitude of the listing location

-   room_type: type of room ('Entire home/apt', 'Private room', or 'Shared room')

-   price: cost for one night booking of the listing (this is what you're predicting; only present in `train.csv`)

-   minimum_nights: minimum number of nights required to book the listing

-   number_of_reviews: number of reviews the listing has

-   last_review: date the last review of the listing was made

-   reviews_per_month: number of reviews the listing gets per month on average

-   calculated_host_listings_count: number of listing the host has

-   availability_365: number of days out of the year the listing is available

```{r}
library(tidyverse)
library(tidymodels)
library(ranger)
library(lubridate)
library(here)
library(patchwork)
library(tidytext)

doParallel::registerDoParallel(cores = 2)

# David Robinson, Sliced Episode 5 - https://github.com/dgrtwo/data-screencasts/blob/master/ml-practice/ep5.Rmd
# Kaggle competition - https://www.kaggle.com/competitions/sliced-s01e05-WXx7h8/data

# Load data ---------------------------------------------------------------

test <- read_csv(here("data/sliced-s01e05/test.csv"),col_types = cols())
train <- read_csv(here("data/sliced-s01e05/train.csv"),col_types = cols()) %>% 
  mutate(price = log1p(price))

read_csv(here("data/sliced-s01e05/sample_submission.csv"))

train_folds <- 
  vfold_cv(train,v = 5)

train_split <- initial_split(train)
```

# Dataset description

```{r}
skimr::skim(train)
```

# EDA

## Price

```{r}
p1 <- train %>% 
  ggplot(aes(price)) +
  geom_histogram(binwidth = 50)

p2 <- train %>% 
  mutate(price = log10(price)) %>% 
  ggplot(aes(price)) +
  geom_histogram()

p1 + p2
```

```{r}
train %>% 
  mutate(price = log10(price)) %>% 
  ggplot(aes(x = latitude, y = longitude,col = neighbourhood_group,fill = price)) +
  geom_point(pch = 21) +
  scale_x_reverse() +
  scale_fill_gradient(low = "green", high = "red")
```

```{r}
train %>% 
  mutate(price = log10(price)) %>% 
  ggplot(aes(price,fct_reorder(neighbourhood_group,price))) +
  geom_violin(draw_quantiles = 0.5)
```

```{r}
train %>% 
  mutate(price = log10(price)) %>% 
  ggplot(aes(number_of_reviews,price)) +
  geom_point() +
  geom_density_2d()
```

```{r}
train %>% 
  mutate(night_grps = fct_lump(factor(minimum_nights),20)) %>% 
  ggplot(aes(x = log10(price + 1), y = night_grps)) +
  geom_violin(draw_quantiles = 0.5)
```

```{r}
train %>% 
  mutate(price = log10(price)) %>% 
  ggplot(aes(minimum_nights,price)) +
  geom_point()
```

```{r}
train %>% 
  #mutate(price = log10(price)) %>% 
  group_by(neighbourhood) %>% 
  summarise(median = median(price),
            n = n()) %>% 
  arrange(median) %>% 
  slice(1:15,(n()-15):n()) %>% 
  ggplot(aes(median,fct_reorder(neighbourhood,median))) +
  geom_point(aes(size = n)) +
  scale_x_continuous(breaks = seq(0,700,50))
```

```{r}
train %>% 
  ggplot(aes(latitude, longitude,col = log10(price))) +
  geom_hex() +
  scale_x_reverse() +
  facet_wrap(~neighbourhood_group)

train %>% 
  ggplot(aes(latitude, longitude,col = neighbourhood_group)) +
  geom_point() +
  scale_x_reverse()
```

```{r}
train %>% 
  ggplot(aes(x = price,y = room_type)) + 
  geom_violin(draw_quantiles = 0.5) +
  geom_label(data = . %>% group_by(room_type) %>% summarise(median = median(price),n = n()),
             aes(x = median,y = room_type,label = paste("n =",n))) +
  scale_x_log10()
```

```{r}
train %>% 
  mutate(calculated_host_listings_count = fct_lump(factor(calculated_host_listings_count),n = 10),
         price = log10(price + 1)) %>% 
  ggplot(aes(x = price, y = calculated_host_listings_count)) +
  ggridges::geom_density_ridges()
```

## Text analysis

```{r}

slice_head_tail <- function(df,size){
  df %>% 
    ungroup() %>% 
    dplyr::slice(1:size,(n()-size+1):n())
}

train %>% 
  mutate(name_no_stop = str_remove_all(name,"\\b(in|the|of|a)(?<=\\b)")) %>% 
  # filter(str_detect(name_no_stop,"in")) %>% 
  # select(name,name_no_stop)
  tidytext::unnest_tokens(text,name_no_stop,token = "ngrams",n = 2) %>% 
  filter(!text %in% stop_words$word) %>%
  group_by(text) %>% 
  summarise(mean_price = mean(price),
            n = n()) %>% 
  filter(n > 200) %>% 
  arrange(-mean_price) %>% 
  slice_head_tail(size = 10) %>% 
  ggplot(aes(mean_price,fct_reorder(text,mean_price),size = n)) +
  geom_point()


```
```{r}
train %>% 
  mutate(name_no_stop = str_remove_all(name,"\\b(in|the|of|a)(?<=\\b)")) %>% 
  # filter(str_detect(name_no_stop,"in")) %>% 
  # select(name,name_no_stop)
  tidytext::unnest_tokens(text,name_no_stop,token = "words",drop = F) %>% 
  filter(!text %in% stop_words$word,str_detect(text,"bed|br")) %>% 
    head(10) %>% 
  pull(name_no_stop) %>% 
    regexplain::regexplain_gadget()

#"bedroom(s)", bed room,"BD","br", "BR", studio, BDR, Rm, Home, Room, bdrm

num_list <- c("one" = "1","two" = "2", "three" = "3", "four" = "4", "five" = "5", "six" = "6")

train %>% 
  mutate(name_no_stop = str_remove_all(name,"\\b(in|the|of|a)(?<=\\b)")) %>% 
  # filter(str_detect(name_no_stop,"in")) %>% 
  # select(name,name_no_stop)
  tidytext::unnest_tokens(text,name_no_stop,token = "words",drop = F) %>% 
  mutate(text = coalesce(num_list[text],text)) %>% 
  group_by(id) %>% 
  summarise(name = paste(text, collapse = " "))
```


# Modelling

## First simple model

```{r}
rf_spec <- rand_forest(
  mtry = tune(),
  trees = 1000,
  min_n = tune()) %>% 
    set_engine(engine = "ranger") %>% 
    set_mode("regression")
```

```{r}

prep_juice <- function(x) prep(x) %>% juice()

abb_rec <- 
  recipe(price ~ neighbourhood_group + longitude + latitude +
           minimum_nights + reviews_per_month + availability_365, data = train) %>% 
  step_dummy(neighbourhood_group) %>% 
  step_impute_median(all_numeric_predictors())
```

### Workflow

```{r}
rf_workflow <- workflow() %>% 
  add_model(rf_spec) %>% 
  add_recipe(abb_rec)
```

### Tune hyperparameters

```{r}
small_train <- train %>% 
  sample_n(8000) %>% 
  vfold_cv(v = 3)

mset <- metric_set(rmse)

# Tuning ------------------------------------------------------------

rf_grid <- grid_max_entropy(
  mtry(range = c(1, 9)),
  min_n(range = c(5,100)),
  size = 15
)

tune_hps <- tune_grid(
  rf_workflow,
  resamples = small_train,
  metrics = mset,
  grid = rf_grid,
  control = control_grid(verbose = TRUE)
)

autoplot(tune_hps)

collect_metrics(tune_hps)
```

```{r}
final_res <- finalize_workflow(rf_workflow,select_best(tune_hps,metric = "rmse")) %>% 
  fit(train)

# Evaluate performance ----------------------------------------------------

final_res %>% 
  predict_holdout()

test %>% select(price) %>% summary
```


```{r}
library(broom)
predict_holdout <- function(wf) {
  wf %>%
    augment(test) %>%
    mutate(.pred = exp(.pred) - 1) %>%
    select(id, price = .pred)
}
augment.last_fit <- function(x, data, ...) {
  bind_cols(data, predict(x, data, ...))
}
```

